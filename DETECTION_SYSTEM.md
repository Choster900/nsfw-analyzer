# üîç Sistema de Detecci√≥n de Contenido Local

## ‚úÖ Caracter√≠sticas

- **100% GRATIS** - Sin API keys, sin billing
- **100% OFFLINE** - Funciona sin internet
- **100% PRIVADO** - Las im√°genes nunca salen del dispositivo
- **Multi-Modal** - Detecta m√∫ltiples tipos de contenido inapropiado

## üéØ Categor√≠as Detectadas

### 1. üîû Contenido Sexual (NSFWJS)
- Pornograf√≠a
- Hentai
- Contenido sugestivo
- Dibujos expl√≠citos

**Precisi√≥n**: Alta (modelo pre-entrenado de Yahoo)

### 2. üí• Violencia
- Contenido violento
- Sangre
- Basado en:
  - Dominancia de color rojo
  - Alto contraste
  - Patrones visuales caracter√≠sticos

**Precisi√≥n**: Media-Alta (an√°lisis heur√≠stico)

### 3. üíä Drogas
- Sustancias ilegales
- Parafernalia
- Basado en:
  - Objetos peque√±os con alto contraste
  - Nitidez de la imagen
  - Densidad de objetos peque√±os

**Precisi√≥n**: Media (an√°lisis heur√≠stico)

### 4. üî´ Armas
- Armas de fuego
- Armas blancas
- Basado en:
  - Formas lineales largas
  - Superficies met√°licas
  - Patrones de contraste

**Precisi√≥n**: Media (an√°lisis heur√≠stico)

## üß† Tecnolog√≠as Utilizadas

1. **NSFWJS** (Yahoo Open Source)
   - Modelo de deep learning para detecci√≥n NSFW
   - Basado en MobileNetV2
   - 93% de precisi√≥n en contenido sexual

2. **TensorFlow.js**
   - Framework de ML para JavaScript
   - Optimizado para React Native
   - Ejecuci√≥n en el dispositivo

3. **An√°lisis Visual Heur√≠stico**
   - Algoritmos de procesamiento de imagen
   - Detecci√≥n de patrones visuales
   - Estad√≠sticas de color y forma

## üìä Funcionamiento

```typescript
Image ‚Üí [NSFWJS Model] ‚Üí Sexual Content Detection
     ‚Üí [Image Statistics] ‚Üí Violence Detection
     ‚Üí [Image Statistics] ‚Üí Drugs Detection
     ‚Üí [Image Statistics] ‚Üí Weapons Detection
     ‚Üí [Combine Results] ‚Üí Final Classification
```

## üöÄ Mejoras Futuras

Para mejorar la precisi√≥n de detecci√≥n de violencia, drogas y armas:

### Opci√≥n 1: Modelos ONNX de HuggingFace
- Descargar modelos pre-entrenados como:
  - `Falconsai/nsfw_image_detection`
  - Modelos de clasificaci√≥n de violencia
  - Modelos de detecci√≥n de objetos (YOLOv5/v8)
- Convertir a formato TensorFlow.js
- Integrar en la app

### Opci√≥n 2: Transfer Learning
- Entrenar modelos custom con TensorFlow
- Usar datasets p√∫blicos:
  - Violence in Movies Dataset
  - Drug Detection Dataset
  - Weapons Detection Dataset
- Fine-tuning de MobileNet o EfficientNet

### Opci√≥n 3: API H√≠brida (opcional)
- Mantener detecci√≥n local para NSFW
- Usar APIs cloud solo para casos edge
- Implementar fallback si hay internet

## üìù Limitaciones Actuales

1. **Violencia/Drogas/Armas**: Basado en heur√≠sticas, no en ML
   - Puede dar falsos positivos
   - Puede perder algunos casos edge
   - Recomendado combinar con revisi√≥n humana

2. **Performance**: An√°lisis en ~2-3 segundos
   - Depende del dispositivo
   - Im√°genes redimensionadas a 224x224

3. **Idioma**: Labels en espa√±ol hardcodeados
   - F√°cil de internacionalizar

## üîß Configuraci√≥n de Sensibilidad

Puedes ajustar los umbrales en `services/localDetection.ts`:

```typescript
// Contenido NSFW
if (pornProb > 0.6) { // Cambiar de 0.6 a 0.7 para ser menos estricto

// Violencia
if (stats.redDominance > 0.6 && stats.contrast > 0.7) { // Ajustar umbrales

// Drogas
if (stats.sharpness > 0.7 && stats.smallObjectDensity > 0.6) { // Ajustar

// Armas
if (stats.linearShapes > 0.6 && stats.metallic > 0.5) { // Ajustar
```

## üì¶ Requisitos

- React Native
- Expo
- TensorFlow.js
- NSFWJS
- ~50MB de espacio para modelos

## üéØ Precisi√≥n Estimada

| Categor√≠a | Precisi√≥n | M√©todo |
|-----------|-----------|--------|
| Pornograf√≠a | ~93% | NSFWJS (ML) |
| Hentai | ~90% | NSFWJS (ML) |
| Violencia | ~70% | Heur√≠stico |
| Drogas | ~65% | Heur√≠stico |
| Armas | ~60% | Heur√≠stico |

**Nota**: Para producci√≥n en casos cr√≠ticos, se recomienda combinar con modelos ML adicionales o revisi√≥n humana.
